{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 LLaMA3.2: Image-to-Text Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fa2d80fb8a4608adb23c4452b16a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import torch\n",
    "\n",
    "login()\n",
    "\n",
    "HF_TOKEN = \"your_huggingface_token_here\"  # Replace with your Hugging Face token\n",
    "\n",
    "# This will be removed in the final version - LLaMA requires access from Meta\n",
    "hf_key = HF_TOKEN\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mahnoo', 'lahlah', 'loonah', 'moomoo', 'nooloo', 'noonoh', 'moolah', 'lahmoo', 'lohmah', 'mahlah', 'tuhkuh', 'kuhkuh', 'teekuh', 'paytee', 'taytuh', 'peepay', 'puhkuh', 'tuhkay', 'puhpee', 'taypuh']\n"
     ]
    }
   ],
   "source": [
    "possible_labels_s_r = [\n",
    "    \"looloo\", \"loolah\", \"looloh\", \"loonoo\", \"loonah\", \"loonoh\", \"loomoo\", \"loomah\", \"loomoh\",\n",
    "    \"lahloo\", \"lahlah\", \"lahloh\", \"lahnoo\", \"lahnah\", \"lahnoh\", \"lahmoo\", \"lahmah\", \"lahmoh\",\n",
    "    \"lohloo\", \"lohlah\", \"lohloh\", \"lohnoo\", \"lohnah\", \"lohnoh\", \"lohmoo\", \"lohmah\", \"lohmoh\",\n",
    "    \"nooloo\", \"noolah\", \"nooloh\", \"noonoo\", \"noonah\", \"noonoh\", \"noomoo\", \"noomah\", \"noomoh\",\n",
    "    \"nahloo\", \"nahlah\", \"nahloh\", \"nahnoo\", \"nahnah\", \"nahnoh\", \"nahmoo\", \"nahmah\", \"nahmoh\",\n",
    "    \"nohloo\", \"nohlah\", \"nohloh\", \"nohnoo\", \"nohnah\", \"nohnoh\", \"nohmoo\", \"nohmah\", \"nohmoh\",\n",
    "    \"mooloo\", \"moolah\", \"mooloh\", \"moonoo\", \"moonah\", \"moonoh\", \"moomoo\", \"moomah\", \"moomoh\",\n",
    "    \"mahloo\", \"mahlah\", \"mahloh\", \"mahnoo\", \"mahnah\", \"mahnoh\", \"mahmoo\", \"mahmah\", \"mahmoh\",\n",
    "    \"mohloo\", \"mohlah\", \"mohloh\", \"mohnoo\", \"mohnah\", \"mohnoh\", \"mohmoo\", \"mohmah\", \"mohmoh\"\n",
    "]\n",
    "\n",
    "possible_labels_p_nr = [\n",
    "    \"teetee\", \"teetuh\", \"teetay\", \"teekee\", \"teekuh\", \"teekay\", \"teepee\", \"teepuh\", \"teepay\",\n",
    "    \"tuhtee\", \"tuhtuh\", \"tuhtay\", \"tuhkee\", \"tuhkuh\", \"tuhkay\", \"tuhpee\", \"tuhpuh\", \"tuhpay\",\n",
    "    \"taytee\", \"taytuh\", \"taytay\", \"taykee\", \"taykuh\", \"taykay\", \"taypee\", \"taypuh\", \"taypay\",\n",
    "    \"keetee\", \"keetuh\", \"keetay\", \"keekee\", \"keekuh\", \"keekay\", \"keepee\", \"keepuh\", \"keepay\",\n",
    "    \"kuhtee\", \"kuhtuh\", \"kuhtay\", \"kuhkee\", \"kuhkuh\", \"kuhkay\", \"kuhpee\", \"kuhpuh\", \"kuhpay\",\n",
    "    \"kaytee\", \"kaytuh\", \"kaytay\", \"kaykee\", \"kaykuh\", \"kaykay\", \"kaypee\", \"kaypuh\", \"kaypay\",\n",
    "    \"peetee\", \"peetuh\", \"peetay\", \"peekee\", \"peekuh\", \"peekay\", \"peepee\", \"peepuh\", \"peepay\",\n",
    "    \"puhtee\", \"puhtuh\", \"puhtay\", \"puhkee\", \"puhkuh\", \"puhkay\", \"puhpee\", \"puhpuh\", \"puhpay\",\n",
    "    \"paytee\", \"paytuh\", \"paytay\", \"paykee\", \"paykuh\", \"paykay\", \"paypee\", \"paypuh\", \"paypay\"\n",
    "]\n",
    "\n",
    "possible_labels_s_r = random.sample(possible_labels_s_r, 10)\n",
    "possible_labels_p_nr = random.sample(possible_labels_p_nr, 10)\n",
    "\n",
    "final_list = possible_labels_s_r + possible_labels_p_nr\n",
    "\n",
    "print(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672e4f7cd1a44b1488dcf511360e78e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Classifying images 0-4:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  0\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.7212, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 0-4:  25%|██▌       | 1/4 [00:33<01:39, 33.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: teekuh.\n",
      "Token probabilities: [0.1089, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8218\n",
      "batch number:  0\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.6409, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 0-4:  50%|█████     | 2/4 [01:04<01:04, 32.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: tuhkuh.\n",
      "Token probabilities: [0.4362, 0.2681, 0.636, 1.0, 1.0]\n",
      "Mean confidence: 0.6681\n",
      "batch number:  0\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.5437, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 0-4:  75%|███████▌  | 3/4 [01:35<00:31, 31.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: peepay.\n",
      "Token probabilities: [0.1229, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8246\n",
      "batch number:  0\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.6408, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 0-4: 100%|██████████| 4/4 [02:07<00:00, 31.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: teekuh.\n",
      "Token probabilities: [0.0842, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 4-8:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  4\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.7227, 1.0, 1.0, 0.8721, 1.0]\n",
      "Mean confidence: 0.9190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 4-8:  25%|██▌       | 1/4 [00:32<01:38, 32.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taytuh\n",
      "Token probabilities: [0.6467, 0.8536, 0.636, 1.0, 0.3486]\n",
      "Mean confidence: 0.6970\n",
      "batch number:  4\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.6132, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 4-8:  50%|█████     | 2/4 [01:04<01:04, 32.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taypuh.\n",
      "Token probabilities: [0.5205, 0.8644, 0.5556, 1.0, 1.0]\n",
      "Mean confidence: 0.7881\n",
      "batch number:  4\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.6064, 1.0, 1.0, 0.7655, 1.0]\n",
      "Mean confidence: 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 4-8:  75%|███████▌  | 3/4 [01:35<00:31, 31.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taytuh.\n",
      "Token probabilities: [0.5263, 0.7491, 0.572, 1.0, 0.8885]\n",
      "Mean confidence: 0.7472\n",
      "batch number:  4\n",
      "Predicted text: noonoh.\n",
      "Token probabilities: [0.2078, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 4-8: 100%|██████████| 4/4 [02:04<00:00, 31.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taytuh.\n",
      "Token probabilities: [0.552, 0.5501, 0.3141, 1.0, 1.0]\n",
      "Mean confidence: 0.6832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 8-12:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  8\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.5608, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 8-12:  25%|██▌       | 1/4 [00:33<01:39, 33.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: peepay.\n",
      "Token probabilities: [0.1206, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8241\n",
      "batch number:  8\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.7276, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 8-12:  50%|█████     | 2/4 [01:04<01:03, 31.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taytuh.\n",
      "Token probabilities: [0.6001, 0.6763, 0.3386, 1.0, 1.0]\n",
      "Mean confidence: 0.7230\n",
      "batch number:  8\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.7517, 0.9031, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 8-12:  75%|███████▌  | 3/4 [01:35<00:31, 31.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taytuh.\n",
      "Token probabilities: [0.5495, 0.6763, 0.3486, 1.0, 1.0]\n",
      "Mean confidence: 0.7149\n",
      "batch number:  8\n",
      "Predicted text: nooloo.\n",
      "Token probabilities: [0.0824, 1.0, 1.0, 0.4389, 1.0]\n",
      "Mean confidence: 0.7043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 8-12: 100%|██████████| 4/4 [02:06<00:00, 31.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: puhpee.\n",
      "Token probabilities: [0.1315, 1.0, 0.2725, 0.3692, 1.0]\n",
      "Mean confidence: 0.5546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 12-16:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  12\n",
      "Predicted text: noonoh.\n",
      "Token probabilities: [0.0835, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.7709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 12-16:  25%|██▌       | 1/4 [00:33<01:40, 33.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: teekuh.\n",
      "Token probabilities: [0.1175, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8235\n",
      "batch number:  12\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.6602, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 12-16:  50%|█████     | 2/4 [01:21<01:24, 42.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taypuh.\n",
      "Token probabilities: [0.5346, 0.7449, 0.5223, 1.0, 1.0]\n",
      "Mean confidence: 0.7604\n",
      "batch number:  12\n",
      "Predicted text: moomoo.\n",
      "Token probabilities: [0.7151, 0.1733, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 12-16:  75%|███████▌  | 3/4 [02:16<00:48, 48.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: puhkuh.\n",
      "Token probabilities: [0.2825, 1.0, 0.8067, 1.0, 1.0]\n",
      "Mean confidence: 0.8178\n",
      "batch number:  12\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.6844, 1.0, 1.0, 0.884, 1.0]\n",
      "Mean confidence: 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 12-16: 100%|██████████| 4/4 [03:10<00:00, 47.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taytuh.\n",
      "Token probabilities: [0.6162, 0.8169, 0.5883, 1.0, 0.539]\n",
      "Mean confidence: 0.7121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 16-20:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  16\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.6883, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 16-20:  25%|██▌       | 1/4 [00:32<01:37, 32.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: tuhkay.\n",
      "Token probabilities: [0.5099, 0.1492, 0.3386, 1.0, 1.0]\n",
      "Mean confidence: 0.5995\n",
      "batch number:  16\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.7491, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 16-20:  50%|█████     | 2/4 [01:03<01:03, 31.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taytuh.\n",
      "Token probabilities: [0.5326, 0.7849, 0.4833, 1.0, 1.0]\n",
      "Mean confidence: 0.7602\n",
      "batch number:  16\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.7239, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 16-20:  75%|███████▌  | 3/4 [01:35<00:31, 31.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taytuh.\n",
      "Token probabilities: [0.5548, 0.8235, 0.4444, 1.0, 1.0]\n",
      "Mean confidence: 0.7645\n",
      "batch number:  16\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.6774, 0.9011, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 16-20: 100%|██████████| 4/4 [02:06<00:00, 31.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: peepay.\n",
      "Token probabilities: [0.1157, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 20-24:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  20\n",
      "Predicted text: lohmah.\n",
      "Token probabilities: [0.0441, 0.5311, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 20-24:  25%|██▌       | 1/4 [00:32<01:38, 32.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taypuh.\n",
      "Token probabilities: [0.4687, 0.796, 0.5056, 1.0, 1.0]\n",
      "Mean confidence: 0.7541\n",
      "batch number:  20\n",
      "Predicted text: nooloo.\n",
      "Token probabilities: [0.1149, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 20-24:  50%|█████     | 2/4 [01:02<01:01, 30.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: paytee.\n",
      "Token probabilities: [0.0846, 1.0, 0.8863, 1.0]\n",
      "Mean confidence: 0.7427\n",
      "batch number:  20\n",
      "Predicted text: moolah\n",
      "Token probabilities: [0.5946, 1.0, 1.0, 0.116]\n",
      "Mean confidence: 0.6776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 20-24:  75%|███████▌  | 3/4 [01:29<00:29, 29.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: teekuh\n",
      "Token probabilities: [0.1164, 1.0, 1.0, 0.2467]\n",
      "Mean confidence: 0.5908\n",
      "batch number:  20\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.8165, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 20-24: 100%|██████████| 4/4 [02:02<00:00, 30.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: puhkuh.\n",
      "Token probabilities: [0.2639, 1.0, 0.7275, 1.0, 1.0]\n",
      "Mean confidence: 0.7983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 24-28:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  24\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.7521, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 24-28:  25%|██▌       | 1/4 [00:39<01:57, 39.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taypuh.\n",
      "Token probabilities: [0.5399, 0.8536, 0.5112, 1.0, 1.0]\n",
      "Mean confidence: 0.7809\n",
      "batch number:  24\n",
      "Predicted text: loonah.\n",
      "Token probabilities: [0.0709, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 24-28:  50%|█████     | 2/4 [01:42<01:46, 53.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taypuh.\n",
      "Token probabilities: [0.4734, 0.8421, 0.5, 1.0, 1.0]\n",
      "Mean confidence: 0.7631\n",
      "batch number:  24\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.732, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 24-28:  75%|███████▌  | 3/4 [02:47<00:58, 58.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: peepay.\n",
      "Token probabilities: [0.0921, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8184\n",
      "batch number:  24\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.7007, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 24-28: 100%|██████████| 4/4 [03:57<00:00, 59.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: taypuh.\n",
      "Token probabilities: [0.5016, 0.8361, 0.5112, 1.0, 1.0]\n",
      "Mean confidence: 0.7698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 28-32:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  28\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.7176, 0.9031, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 28-32:  25%|██▌       | 1/4 [00:32<01:37, 32.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: puhkuh.\n",
      "Token probabilities: [0.1982, 1.0, 0.895, 1.0, 1.0]\n",
      "Mean confidence: 0.8186\n",
      "batch number:  28\n",
      "Predicted text: nooloo.\n",
      "Token probabilities: [0.0709, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 28-32:  50%|█████     | 2/4 [01:03<01:03, 31.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: teekuh.\n",
      "Token probabilities: [0.0896, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.8179\n",
      "batch number:  28\n",
      "Predicted text: moolah.\n",
      "Token probabilities: [0.7701, 1.0, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.9540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 28-32:  75%|███████▌  | 3/4 [01:34<00:31, 31.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: tuhkuh.\n",
      "Token probabilities: [0.6274, 0.5611, 0.884, 1.0, 1.0]\n",
      "Mean confidence: 0.8145\n",
      "batch number:  28\n",
      "Predicted text: loonah.\n",
      "Token probabilities: [0.155, 1.0, 0.833, 1.0]\n",
      "Mean confidence: 0.7470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 28-32: 100%|██████████| 4/4 [02:02<00:00, 30.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: peepay.\n",
      "Token probabilities: [0.1037, 1.0, 1.0, 0.8991, 1.0]\n",
      "Mean confidence: 0.8006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 32-34:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  32\n",
      "Predicted text: loonah.\n",
      "Token probabilities: [0.103, 1.0, 1.0, 1.0]\n",
      "Mean confidence: 0.7757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 32-34:  50%|█████     | 1/2 [00:28<00:28, 28.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: puhkuh.\n",
      "Token probabilities: [0.1921, 1.0, 0.8299, 1.0, 1.0]\n",
      "Mean confidence: 0.8044\n",
      "batch number:  32\n",
      "Predicted text: loonah.\n",
      "Token probabilities: [0.1393, 1.0, 0.8135, 1.0]\n",
      "Mean confidence: 0.7382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying images 32-34: 100%|██████████| 2/2 [00:56<00:00, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: tuhkuh.\n",
      "Token probabilities: [0.5955, 0.4117, 0.7887, 1.0, 1.0]\n",
      "Mean confidence: 0.7592\n",
      "Classification complete. Results saved to CSV files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class ImageTextMatcher:\n",
    "    def __init__(self, image_folder=\"images\"):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with the path to the image folder.\n",
    "        \n",
    "        Args:\n",
    "            image_folder: Path to the folder containing images\n",
    "        \"\"\"\n",
    "        self.image_folder = image_folder\n",
    "        self.results = []\n",
    "        self.models = {}\n",
    "        \n",
    "    def load_model(self, model_name):\n",
    "        \"\"\"\n",
    "        Load a multimodal model.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Name of the model to load ('llama')\n",
    "        \"\"\"\n",
    "        if model_name == 'llama':\n",
    "            processor = AutoProcessor.from_pretrained(\"meta-llama/Llama-3.2-11B-Vision-Instruct\")\n",
    "            model = MllamaForConditionalGeneration.from_pretrained(\n",
    "                \"meta-llama/Llama-3.2-11B-Vision-Instruct\",\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "            self.models['llama'] = {'model': model, 'processor': processor}\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}, Model not Found.\")\n",
    "\n",
    "    def classify_image(self, image_path, possible_labels):\n",
    "        \"\"\"\n",
    "        Classify the image based on possible labels and calculate confidence score.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the image file\n",
    "            possible_labels: List of possible labels (S-R or P-NR)\n",
    "            \n",
    "        Returns:\n",
    "            Predicted label and confidence score\n",
    "        \"\"\"\n",
    "        model_info = self.models['llama']\n",
    "        model = model_info['model']\n",
    "        processor = model_info['processor']\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Prompt setup\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": f\"You are given an image for which you need to assign a label. Use one of the following labels: {possible_labels}. Only respond with the label.\"}\n",
    "            ]}\n",
    "        ]\n",
    "\n",
    "        input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "        inputs = processor(\n",
    "            image,\n",
    "            input_text,\n",
    "            add_special_tokens=False,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "        \n",
    "        # Generate classification\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=5,\n",
    "                output_scores=True,\n",
    "                return_dict_in_generate=True,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                top_k=40\n",
    "            )\n",
    "\n",
    "            generated_token_ids = outputs.sequences[0][inputs['input_ids'].size(1):] # Only new tokens\n",
    "            scores = outputs.scores # Logits for each new token\n",
    "\n",
    "            token_probs = []\n",
    "            for i, token_id in enumerate(generated_token_ids):\n",
    "                logits = scores[i] # Logits for i-th token\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                token_prob = probs[0, token_id]\n",
    "                token_probs.append(token_prob.item())\n",
    "\n",
    "            # Final predicted text (after decoding tokens)\n",
    "            predicted_text = processor.tokenizer.decode(generated_token_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "            # Confidence score (mean of token probabilities)\n",
    "            confidence_score = sum(token_probs) / len(token_probs)\n",
    "\n",
    "            print(f\"Predicted text: {predicted_text}\")\n",
    "            print(f\"Token probabilities: {[round(p, 4) for p in token_probs]}\")\n",
    "            print(f\"Mean confidence: {confidence_score:.4f}\")\n",
    "\n",
    "            return predicted_text, confidence_score\n",
    "\n",
    "    def prepare_dataset_for_classification(self, image_paths=None):\n",
    "        \"\"\"\n",
    "        Prepare dataset for image classification.\n",
    "        \n",
    "        Args:\n",
    "            image_paths: List of paths to images (if None, scan the image folder)\n",
    "            \n",
    "        Returns:\n",
    "            List of image paths\n",
    "        \"\"\"\n",
    "        # If image paths are not provided, scan the image folder\n",
    "        if image_paths is None:\n",
    "            image_paths = []\n",
    "            for filename in os.listdir(self.image_folder):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                    image_paths.append(os.path.join(self.image_folder, filename))\n",
    "        \n",
    "        return image_paths\n",
    "    \n",
    "    def classify_dataset(self, model_name, image_paths, possible_labels_s_r, possible_labels_p_nr):\n",
    "        \"\"\"\n",
    "        Classify a dataset of images using S-R and P-NR labels and calculate confidence scores.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Name of the model to use\n",
    "            image_paths: List of image paths to classify\n",
    "            possible_labels_s_r: Labels for sonorant+rounded pseudowords\n",
    "            possible_labels_p_nr: Labels for plosief+non-rounded pseudowords\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with classification results\n",
    "        \"\"\"\n",
    "        if model_name not in self.models:\n",
    "            self.load_model(model_name)\n",
    "        \n",
    "        classification_results = []\n",
    "\n",
    "        # Classify images in batches of 4\n",
    "        batch_size = 4\n",
    "        for i in range(0, len(image_paths), batch_size):\n",
    "            batch = image_paths[i:i+batch_size]\n",
    "            \n",
    "            for image_path in tqdm(batch, desc=f\"Classifying images {i}-{i+len(batch)}\"):\n",
    "                print(\"batch number: \", i)\n",
    "                try:\n",
    "                    # First classify with S-R labels\n",
    "                    predicted_class_s_r, score_s_r = self.classify_image(image_path, possible_labels_s_r)\n",
    "                    \n",
    "                    # Then classify with P-NR labels\n",
    "                    predicted_class_p_nr, score_p_nr = self.classify_image(image_path, possible_labels_p_nr)\n",
    "\n",
    "                    filename = os.path.basename(image_path)\n",
    "                    image_type = 'Unknown'\n",
    "                    if 'curved' in filename.lower():\n",
    "                        image_type = 'Curved'\n",
    "                    elif 'jagged' in filename.lower():\n",
    "                        image_type = 'Jagged'\n",
    "                                \n",
    "                    # Store result with confidence scores\n",
    "                    classification_results.append({\n",
    "                        'image_path': image_path,\n",
    "                        'image_filename': os.path.basename(image_path),\n",
    "                        'image_type': image_type,\n",
    "                        'predicted_class_s_r': predicted_class_s_r,\n",
    "                        'score_s_r': score_s_r,\n",
    "                        'predicted_class_p_nr': predicted_class_p_nr,\n",
    "                        'score_p_nr': score_p_nr\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error classifying {image_path}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "            # Clear CUDA cache between batches\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        return pd.DataFrame(classification_results)\n",
    "\n",
    "    def analyze_classification_results(self, results_df):\n",
    "        \"\"\"\n",
    "        Analyze the classification results.\n",
    "        \n",
    "        Args:\n",
    "            results_df: DataFrame with classification results\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with classification metrics\n",
    "        \"\"\"\n",
    "        # Extract and analyze the scores for S-R and P-NR words\n",
    "        curved_scores_s_r = results_df[results_df['image_type'] == 'Curved']['score_s_r']\n",
    "        jagged_scores_s_r = results_df[results_df['image_type'] == 'Jagged']['score_s_r']\n",
    "        \n",
    "        curved_scores_p_nr = results_df[results_df['image_type'] == 'Curved']['score_p_nr']\n",
    "        jagged_scores_p_nr = results_df[results_df['image_type'] == 'Jagged']['score_p_nr']\n",
    "        \n",
    "        # Compare average scores\n",
    "        analysis_results = {\n",
    "            'avg_score_s_r_curved': curved_scores_s_r.mean(),\n",
    "            'avg_score_s_r_jagged': jagged_scores_s_r.mean(),\n",
    "            'avg_score_p_nr_curved': curved_scores_p_nr.mean(),\n",
    "            'avg_score_p_nr_jagged': jagged_scores_p_nr.mean()\n",
    "        }\n",
    "\n",
    "        return pd.DataFrame([analysis_results])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize\n",
    "    matcher = ImageTextMatcher(image_folder=\"images\")\n",
    "    image_paths = matcher.prepare_dataset_for_classification()\n",
    "    classification_results = matcher.classify_dataset(\"llama\", image_paths, possible_labels_s_r, possible_labels_p_nr)\n",
    "\n",
    "\n",
    "    ## Change folder to [1,2,3]\n",
    "    # Save results\n",
    "    classification_results.to_csv(\"10/image_classifications.csv\", index=False)\n",
    "    \n",
    "    # Save metrics\n",
    "    classification_metrics = matcher.analyze_classification_results(classification_results)\n",
    "    classification_metrics.to_csv(\"10/classification_metrics.csv\", index=False)\n",
    "    \n",
    "    print(\"Classification complete. Results saved to CSV files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
